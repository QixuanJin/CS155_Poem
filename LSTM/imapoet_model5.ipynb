{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from pickle import dump\n",
    "from pickle import load \n",
    "from keras.models import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train only on shakespeare data\n",
    "X = load(open(\"X_training_shakespeare_final.h5\", \"rb\"))\n",
    "y = load(open(\"y_training_shakespeare_final.h5\", \"rb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = load(open(\"mapping.pkl\", \"rb\"))\n",
    "vocab_size = len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will initialize the first LSTM layer \n",
    "# and the last softmax Dense layer of\n",
    "# our new double-layer LSTM model with the \n",
    "# pretrained layers from Model 4\n",
    "prev_model = load_model(\"model4_3.h5\")\n",
    "prev_LSTM_layer = prev_model.layers[0]\n",
    "prev_Dense_layer = prev_model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-stacked LSTM architecture (Model 5)\n",
    "# We added a Dropout layer and another 120 units LSTM layer \n",
    "model = Sequential()\n",
    "model.add(LSTM(120, return_sequences=True, input_shape = (X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(120))\n",
    "model.add(Dense(len(mapping), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 40, 120)           86880     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 120)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 120)               115680    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                7260      \n",
      "=================================================================\n",
      "Total params: 209,820\n",
      "Trainable params: 209,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Initialize with pretrained weights\n",
    "model.layers[0].set_weights(prev_LSTM_layer.get_weights())\n",
    "model.layers[3].set_weights(prev_Dense_layer.get_weights())\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "91478/91478 [==============================] - 338s 4ms/step - loss: 1.6277 - acc: 0.5067\n"
     ]
    }
   ],
   "source": [
    "# Model 5 training conditions \n",
    "# Saved model every 5 epochs\n",
    "# Total 30 epochs\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs = 5, batch_size = 32, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
