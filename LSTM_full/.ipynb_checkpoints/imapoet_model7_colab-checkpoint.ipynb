{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, concatenate, BatchNormalization, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from pickle import dump\n",
    "from pickle import load \n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Colab pipeline meant for continuing model training \n",
    "# We load the processed character text instead of the ready-to-run X and y data\n",
    "# because uploading X and y data usually too large to upload. \n",
    "# We repeat the preprocessing steps \n",
    "with open(\"process_shakespeare_final.txt\", \"rb\") as fp: \n",
    "    char_text = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = load(open(\"mapping.pkl\", \"rb\"))\n",
    "vocab_size = len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91786\n"
     ]
    }
   ],
   "source": [
    "length = 40 + 1\n",
    "sequences = []\n",
    "for i in range(length, len(char_text)): \n",
    "    seq = char_text[i-length:i]\n",
    "    seq_string = ''.join(seq)\n",
    "    sequences.append(seq_string)\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "num_char = []\n",
    "for line in sequences: \n",
    "    encoded = [mapping[char] for char in line]\n",
    "    num_char.append(encoded)\n",
    "print(len(num_char[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91786, 40)\n",
      "(91786,)\n"
     ]
    }
   ],
   "source": [
    "num_char = np.array(num_char)\n",
    "X, y = num_char[:, :-1], num_char[:, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91786, 40, 60)\n",
      "(91786, 60)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([to_categorical(x, num_classes=len(mapping)) for x in X])\n",
    "y = to_categorical(y, num_classes=len(mapping))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running locally, you can load directly and then stack \n",
    "with open(\"X_training_shakespeare_final.h5\", \"rb\") as fp: \n",
    "    X = pickle.load(fp)\n",
    "with open(\"y_training_shakespeare_final.h5\", \"rb\") as fp: \n",
    "    y = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input_1 (InputLayer)       (None, 40, 60)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "x_1 (LSTM)                      (None, 120)          86880       char_input_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 120)          0           x_1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 120)          14520       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 120)          480         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 120)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 120)          14520       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "char_input_2 (InputLayer)       (None, 40, 60)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 120)          480         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "y_1 (LSTM)                      (None, 40, 120)      86880       char_input_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 120)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 40, 120)      0           y_1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 120)          14520       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "y_2 (LSTM)                      (None, 40, 120)      115680      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 120)          480         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "y_3 (LSTM)                      (None, 120)          115680      y_2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 120)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 240)          0           y_3[0][0]                        \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 120)          28920       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 60)           7260        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "extra (Dense)                   (None, 60)           7260        activation_9[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 493,560\n",
      "Trainable params: 492,840\n",
      "Non-trainable params: 720\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load from latest version of model 5 to continue training\n",
    "model = load_model(\"model7_2.h5\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], loss_weights=[1, 0.2])\n",
    "model.fit([X, X], [y, y], epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "filename = \"model7_3.h5\"\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from colab to local disk\n",
    "from google.colab import files\n",
    "files.download(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
